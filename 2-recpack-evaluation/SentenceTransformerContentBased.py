# pip install --user annoy
# https://github.com/spotify/annoy
import numpy as np
from annoy import AnnoyIndex
from recpack.algorithms.base import Algorithm
from scipy.sparse import lil_matrix, csr_matrix
from sentence_transformers import SentenceTransformer


class SentenceTransformerContentBased(Algorithm):
    """
    Content-based recommendation algorithm using Sentence Transformers and Annoy.

    Embeds item content using a Sentence Transformer model. User profiles are
    generated by averaging the embeddings of items they interacted with.
    Annoy (Approximate Nearest Neighbors Oh Yeah) is used to find candidate
    items for recommendation based on user profile similarity.

    Args:
        language (str): The Sentence Transformer model to use (e.g., 'all-MiniLM-L6-v2').
                        Defaults to 'all-MiniLM-L6-v2'.
        content (dict): A dictionary mapping item IDs (int) to their textual content (str).
        metric (str): The distance metric for Annoy ('angular', 'euclidean', 'manhattan',
                      'hamming', 'dot'). Defaults to 'dot'.
        embedding_dim (int | None): The dimension of the sentence embeddings. If None,
                                    it's inferred from the model. Defaults to None.
        n_trees (int): Number of trees for the Annoy index. More trees give higher
                       precision but use more memory. Defaults to 10.
        num_neighbors (int): The number of neighbors (recommendations) to retrieve
                             for each user. Defaults to 100.
        user_offset_factor (int): A factor to ensure user IDs in Annoy are distinct
                                  from item IDs. User ID in Annoy = actual_user_id + user_offset.
                                  Defaults to 1. Can be increased if item IDs might overlap
                                  with user IDs + num_items.
    """

    def __init__(self, content: dict, language: str = 'all-MiniLM-L6-v2', metric: str = "dot", embedding_dim: int | None = None, n_trees: int = 10, num_neighbors: int = 100, user_offset_factor: int = 1):
        super().__init__()  # Initialize the base Algorithm class
        self.sentencetransformer = SentenceTransformer(language)

        # Infer embedding dimension if not provided
        if embedding_dim is None:
            # Encode a dummy text to get the embedding dimension
            dummy_embedding = self.sentencetransformer.encode("dummy text")
            self._embedding_dim = dummy_embedding.shape[0]
        else:
            self._embedding_dim = embedding_dim

        self.annoy_index = AnnoyIndex(self._embedding_dim, metric)
        self.n_trees = n_trees
        self.content = content  # {item_id: "item description"}
        self._user_offset_factor = user_offset_factor
        self._user_offset = None  # Will be calculated in _fit
        self.num_neighbors = num_neighbors
        self._metric = metric
        self._users_in_annoy = set()  # Keep track of users successfully added

    def _fit(self, X: csr_matrix):
        num_U, num_I = X.shape
        # Ensure user IDs are distinct from item IDs
        self._user_offset = num_I * self._user_offset_factor
        self._users_in_annoy = set()  # Reset for fitting

        print(f"Fitting {self.__class__.__name__}:")
        print(f"  Items: {num_I}, Users: {num_U}")
        print(f"  Embedding dimension: {self._embedding_dim}")
        print(f"  User offset: {self._user_offset}")

        # 1. Add items to Annoy index
        print("  Adding items to Annoy index...")
        items_added = 0
        for item_id in self.content.keys():
            content_text = self.content.get(item_id, None)
            if content_text:
                embedding = self.sentencetransformer.encode(content_text)
                self.annoy_index.add_item(item_id, embedding)
                items_added += 1
            # else: handle items with no content if necessary (e.g., skip or use default embedding)
        print(f"    Added {items_added}/{num_I} items with content.")

        # 2. Create user embeddings and add users to Annoy index
        print("  Creating user embeddings and adding users to Annoy index...")
        users_added = 0
        for user_id in range(num_U):
            items_interacted_indices = X[user_id].nonzero()[1]

            if len(items_interacted_indices) > 0:
                item_embeddings = []
                for item_id in items_interacted_indices:
                    # Check if item was added to Annoy (i.e., had content)
                    # Use get_item_vector which raises IndexError if item not found
                    try:
                        item_embedding = self.annoy_index.get_item_vector(
                            item_id)
                        item_embeddings.append(item_embedding)
                    except IndexError:
                        # Item wasn't added, likely due to missing content. Skip.
                        pass

                if item_embeddings:
                    # Calculate average embedding for the user
                    user_embedding = np.mean(item_embeddings, axis=0)
                    # Add the user to the annoy index with an offset
                    annoy_user_id = user_id + self._user_offset
                    self.annoy_index.add_item(annoy_user_id, user_embedding)
                    # Track users successfully added
                    self._users_in_annoy.add(user_id)
                    users_added += 1
        print(
            f"    Added {users_added}/{num_U} users with valid interaction history.")

        # 3. Build the Annoy index
        print("  Building Annoy index...")
        self.annoy_index.build(self.n_trees)
        print("  Fit complete.")

    # X is often unused in prediction for CB, but kept for interface consistency
    def _predict(self, X: csr_matrix):
        num_U, num_I = X.shape
        if self._user_offset is None:
            raise RuntimeError("The model must be fitted before prediction.")

        result = lil_matrix((num_U, num_I), dtype=np.float32)

        print(f"Predicting recommendations for {num_U} users...")

        for user_id in range(num_U):
            if user_id not in self._users_in_annoy:
                # Skip users who couldn't be added during fit (e.g., no interactions)
                continue

            annoy_user_id = user_id + self._user_offset

            try:
                # Query Annoy for nearest items
                # Search for more items than needed initially to allow filtering
                # search_k=-1 means Annoy will inspect n_trees * n_items nodes
                nn_indices, nn_distances = self.annoy_index.get_nns_by_item(
                    annoy_user_id, num_I + num_U, search_k=-1, include_distances=True
                )

                user_embedding = self.annoy_index.get_item_vector(
                    annoy_user_id)

                potential_recs = []
                user_interactions = set(X[user_id].nonzero()[1])

                for item_idx, dist in zip(nn_indices, nn_distances):
                    # Filter out users and items already interacted with
                    if item_idx < self._user_offset and item_idx not in user_interactions:
                        try:
                            item_embedding = self.annoy_index.get_item_vector(
                                item_idx)
                            # Calculate dot product similarity
                            # Note: If metric is 'dot', Annoy returns sqrt(2 - 2*dot_product)
                            # If metric is 'angular', Annoy returns sqrt(2*(1-cos(angle)))
                            # We recalculate dot product for clarity and metric independence here
                            score = np.dot(user_embedding, item_embedding)
                            potential_recs.append((item_idx, score))
                        except IndexError:
                            # Item might not exist in index if filtered during fit, ignore.
                            pass

                # Sort potential recommendations by score (higher is better)
                potential_recs.sort(key=lambda x: x[1], reverse=True)

                # Get top N recommendations
                top_recs = potential_recs[:self.num_neighbors]

                # Populate the result matrix
                for item_id, score in top_recs:
                    result[user_id, item_id] = score

            except IndexError:
                # This user_id + offset was not found in Annoy (shouldn't happen due to self._users_in_annoy check, but safeguard)
                print(
                    f"Warning: User {user_id} (Annoy ID {annoy_user_id}) not found in Annoy index during prediction.")
                continue
            except Exception as e:
                print(f"Error predicting for user {user_id}: {e}")
                continue

        print("Prediction complete.")
        return result.tocsr()
